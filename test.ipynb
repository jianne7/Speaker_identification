{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler, RandomSampler, BatchSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"/Users/ujinne/python/Hackathon/speaker_recognition/data/train\"\n",
    "# path = \"/Users/ujinne/python/Hackathon/speaker_recognition/data/sample/feature/train/\"\n",
    "path = \"/Users/ujinne/python/Hackathon/speaker_recognition/data/sample/train/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "MelSpectrogram = T.MelSpectrogram(sample_rate=16000,\n",
    "                                  n_fft=512,\n",
    "                                  win_length=400,\n",
    "                                  hop_length = 160,\n",
    "                                  n_mels = 40)\n",
    "    \n",
    "AmplitudeToDB = T.AmplitudeToDB()\n",
    "\n",
    "def wav2melspectrogram(filepath: str):\n",
    "    samples, sample_rate = torchaudio.load(filepath)\n",
    "    assert sample_rate == 16000, \"Sampling Rate != 16000\"\n",
    "\n",
    "    mel_specgram = MelSpectrogram(samples)\n",
    "    mel_specgram = AmplitudeToDB(mel_specgram)\n",
    "    mel_specgram = mel_specgram.squeeze(0).transpose(0, 1).contiguous()\n",
    "\n",
    "    return mel_specgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = glob.glob(path + '/*')\n",
    "# files = sorted([f for f in files if f != \".DS_Store\"])\n",
    "\n",
    "files = sorted([f.split('/')[-1] for f in glob.glob(path + '/*') if os.path.isdir(f)])\n",
    "# len(f_list)\n",
    "# files = files[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 42653.94it/s]\n"
     ]
    }
   ],
   "source": [
    "spk_id_list = []\n",
    "for f in tqdm(files):\n",
    "    spk_id = f.split('/')[-1]\n",
    "    spk_id_list.append(spk_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0CAE3COBqO', '6cmw8oKHST', '7K4iJllpGl']"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spk_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([547, 40])\n",
      "tensor([[-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        ...,\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.]])\n",
      "torch.Size([717, 40])\n",
      "tensor([[-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        ...,\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.]])\n",
      "torch.Size([564, 40])\n",
      "tensor([[-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        ...,\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.]])\n",
      "torch.Size([444, 40])\n",
      "tensor([[-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        ...,\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.]])\n",
      "torch.Size([461, 40])\n",
      "tensor([[-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        ...,\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.]])\n",
      "torch.Size([666, 40])\n",
      "tensor([[-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        ...,\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.]])\n"
     ]
    }
   ],
   "source": [
    "batch = []\n",
    "for i in range(len(spk_id_list)):\n",
    "    spk_id = spk_id_list[i]\n",
    "    utts = glob.glob(f'{path}/{spk_id}/*.pt')\n",
    "\n",
    "    mel_spec_tensor_list = []\n",
    "    # if len(utts) >= 10:\n",
    "    #     utt_list = random.sample(utts, 10)\n",
    "    # else:\n",
    "    #     utt_list = random.choices(utts, k=10)\n",
    "\n",
    "    # for utt in utt_list:\n",
    "    for utt in utts:\n",
    "        # print(utt)\n",
    "        # mel_spectrogram_tensor = wav2melspectrogram(utt)\n",
    "        mel_spec_tensor = torch.load(utt)\n",
    "        print(mel_spec_tensor.shape)\n",
    "        print(mel_spec_tensor)\n",
    "        mel_spec_tensor_list.append(mel_spec_tensor)\n",
    "    batch.append(mel_spec_tensor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([666, 40])\n",
      "tensor([[-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        ...,\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.]])\n",
      "torch.Size([666, 40])\n",
      "tensor([[-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        ...,\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.]])\n",
      "torch.Size([666, 40])\n",
      "tensor([[-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        ...,\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.]])\n",
      "torch.Size([666, 40])\n",
      "tensor([[-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        ...,\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.]])\n",
      "torch.Size([666, 40])\n",
      "tensor([[-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        ...,\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.]])\n",
      "torch.Size([666, 40])\n",
      "tensor([[-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        ...,\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.]])\n"
     ]
    }
   ],
   "source": [
    "batch = []\n",
    "for i in range(len(spk_id_list)):\n",
    "    spk_id = spk_id_list[i]\n",
    "    utts = glob.glob(f'{path}/{spk_id}/*.wav')\n",
    "\n",
    "    mel_spec_tensor_list = []\n",
    "    # if len(utts) >= 10:\n",
    "    #     utt_list = random.sample(utts, 10)\n",
    "    # else:\n",
    "    #     utt_list = random.choices(utts, k=10)\n",
    "\n",
    "    # for utt in utt_list:\n",
    "    for utt in utts:\n",
    "        # print(utt)\n",
    "        mel_spectrogram_tensor = wav2melspectrogram(utt)\n",
    "        print(mel_spec_tensor.shape)\n",
    "        print(mel_spec_tensor)\n",
    "        mel_spec_tensor_list.append(mel_spec_tensor)\n",
    "    batch.append(mel_spec_tensor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zuqaTALtAS_1.pt'"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utt.split('/')[-1].replace(\".wav\", \".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len_time: 547\n",
      "len_time_2: 398\n",
      "len_time: 717\n",
      "len_time_2: 568\n",
      "len_time: 564\n",
      "len_time_2: 415\n",
      "len_time: 444\n",
      "len_time_2: 295\n",
      "len_time: 666\n",
      "len_time_2: 517\n",
      "len_time: 461\n",
      "len_time_2: 312\n",
      "len_time: 768\n",
      "len_time_2: 619\n",
      "len_time: 436\n",
      "len_time_2: 287\n",
      "len_time: 291\n",
      "len_time_2: 142\n",
      "len_time: 265\n",
      "len_time_2: 116\n"
     ]
    }
   ],
   "source": [
    "sampling_frame_length = random.randint(140, 180)\n",
    "melspec_list = []\n",
    "\n",
    "for mel_spectrogram_tensor_list in batch:\n",
    "    for utt_tensor in mel_spectrogram_tensor_list:\n",
    "        len_time = utt_tensor.size(0)\n",
    "        print(f'len_time: {len_time}')\n",
    "        len_time = len_time - sampling_frame_length\n",
    "        print(f'len_time_2: {len_time}')\n",
    "\n",
    "        start_time = random.randint(0, len_time)\n",
    "        end_time = start_time + sampling_frame_length\n",
    "        \n",
    "        melspec_list.append(utt_tensor[start_time:end_time, :])\n",
    "\n",
    "mel_spec_tensors = torch.stack(melspec_list) # [batch_size, time_step, feature_dim] batch_size = N * M의 형태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 149, 40])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel_spec_tensors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self,input_size=40, hidden_size=768, num_layers=3, batch_size=1):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.layers = nn.Linear(self.hidden_size, 256)\n",
    "        self.batch_size = batch_size\n",
    "        self.lstm = nn.LSTM(self.input_size, self.hidden_size, self.num_layers, batch_first = True)\n",
    " \n",
    "    def forward(self, x):\n",
    "#         print(x.shape)\n",
    "        # x = x.squeeze(0)\n",
    "        self.lstm.flatten_parameters()\n",
    "        y,_ = self.lstm(x)\n",
    "        y = self.layers(y[:,-1,:]) # (BS, T, emb_dim)\n",
    "        \n",
    "        y = y / torch.norm(y, p=2, dim=1, keepdim=True) # (BS, emb_dim)\n",
    "        # y = y.sum(1) / y.size(1) # (emb_dim), average pooling over time frames\n",
    "#         y = torch.mean(y, dim=1)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "def get_LSTM_model(input_size, hidden_size, num_layers, batch_size):\n",
    "    LSTM_model = LSTM(input_size, hidden_size, num_layers, batch_size)\n",
    "    \n",
    "    return LSTM_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 40\n",
    "hidden_size = 768\n",
    "num_layers = 3\n",
    "batch_size = 10\n",
    "\n",
    "LSTM_model = get_LSTM_model(input_size, hidden_size, num_layers, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "x = mel_spec_tensors[0].unsqueeze(0)\n",
    "y, _ = lstm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 149, 768])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 149, 40])\n",
      "torch.Size([10, 256])\n"
     ]
    }
   ],
   "source": [
    "# x = x.unsqueeze(0)\n",
    "x = mel_spec_tensors\n",
    "print(x.shape)\n",
    "dvecs = LSTM_model(x) # [batch_size, emb_dim]\n",
    "print(dvecs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch_size는 N(화자의 수) * M(발화 개수) 였으므로 5*2 = 10이됨\n",
    "\n",
    "그걸 view를 통해 [N, M, -1] shape으로 바꿔주면서 [5, 2, 256]이 되는 것 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2, 256])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dvecs = dvecs.view(5, 2, -1) # [N, M, emb_dim] 으로 바꿔야함\n",
    "dvecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 256])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(dvecs, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
       "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stepsize = 64\n",
    "label = torch.from_numpy(np.asarray(range(0,stepsize)))\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,\n",
       "         3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  5,  5,  5,  5,\n",
       "         5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  7,  7,\n",
       "         7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
       "         9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "        10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12,\n",
       "        12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14,\n",
       "        14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16,\n",
       "        16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "        18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19,\n",
       "        19, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21,\n",
       "        21, 21, 21, 21, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23,\n",
       "        23, 23, 23, 23, 23, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26,\n",
       "        27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 28,\n",
       "        28, 28, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 30, 30, 30, 30, 30, 30,\n",
       "        30, 30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 32, 32, 32, 32,\n",
       "        32, 32, 32, 32, 32, 32, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 34, 34,\n",
       "        34, 34, 34, 34, 34, 34, 34, 34, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35,\n",
       "        36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 39, 39, 39, 39, 39, 39,\n",
       "        39, 39, 39, 39, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 41, 41, 41, 41,\n",
       "        41, 41, 41, 41, 41, 41, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 43, 43,\n",
       "        43, 43, 43, 43, 43, 43, 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44,\n",
       "        45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 46, 46, 46, 46, 46, 46, 46, 46,\n",
       "        46, 46, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 48, 48, 48, 48, 48, 48,\n",
       "        48, 48, 48, 48, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 50, 50, 50, 50,\n",
       "        50, 50, 50, 50, 50, 50, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 52, 52,\n",
       "        52, 52, 52, 52, 52, 52, 52, 52, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53,\n",
       "        54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 55, 55, 55, 55, 55, 55, 55, 55,\n",
       "        55, 55, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 57, 57, 57, 57, 57, 57,\n",
       "        57, 57, 57, 57, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 59, 59, 59, 59,\n",
       "        59, 59, 59, 59, 59, 59, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 61, 61,\n",
       "        61, 61, 61, 61, 61, 61, 61, 61, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62,\n",
       "        63, 63, 63, 63, 63, 63, 63, 63, 63, 63])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsize = 10\n",
    "target = torch.repeat_interleave(label,repeats=gsize,dim=0)\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim_matrix = torch.rand(64, 10, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cos_sim_matrix.view(-1, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([640, 64])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim_matrix.view(-1, 64).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_loss_softmax(dvecs, cos_sim_matrix):\n",
    "    '''\n",
    "    Calculates the loss on each embedding $L(e_{ji})$ by taking softmax\n",
    "    '''\n",
    "    N, M, _ = dvecs.shape\n",
    "    L = []\n",
    "    for j in range(N):\n",
    "        L_row = []\n",
    "        for i in range(M):\n",
    "            L_row.append(-F.log_softmax(cos_sim_matrix[j,i], 0)[j])\n",
    "        L_row = torch.stack(L_row)\n",
    "        L.append(L_row)\n",
    "    return torch.stack(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10, 256])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dvecs = torch.rand(64, 10, 256)\n",
    "dvecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "L = embed_loss_softmax(dvecs, cos_sim_matrix)\n",
    "print(embed_loss_softmax(dvecs, cos_sim_matrix).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(42.4982)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "loss = criterion(cos_sim_matrix.view(-1, stepsize), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.1911)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t() #transpose\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec = accuracy(cos_sim_matrix.view(-1,stepsize).detach(), torch.repeat_interleave(label,repeats=gsize,dim=0).detach(), topk=(1,))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.0312])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7531, 0.1310],\n",
       "         [0.1752, 0.2394]],\n",
       "\n",
       "        [[0.7106, 0.2597],\n",
       "         [0.2194, 0.1900]]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(2,2,2)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7531, 0.1310],\n",
       "        [0.1752, 0.2394],\n",
       "        [0.7106, 0.2597],\n",
       "        [0.2194, 0.1900]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.view(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_val(train_dir, split_path, val_ratio=0.2):\n",
    "    speakers = [x for x in train_dir.iterdir() if x.is_dir()]\n",
    "    print(\"Found \", len(speakers), \"speakers\")\n",
    "    wav_list = []\n",
    "    split_list = []\n",
    "    for id_ in tqdm(speakers):\n",
    "        utterences = ['/'.join(x.parts[-2:]) for x in id_.glob(\"*.wav\")]\n",
    "        split_list.extend((np.random.rand(len(utterences)) > val_ratio).astype(int))\n",
    "        wav_list.extend(utterences)\n",
    "    # save split.txt\n",
    "    with open(split_path, \"w\") as split:\n",
    "        for i, n in enumerate(split_list):\n",
    "            split.write(\"%d %s\\n\" % (n, wav_list[i]))\n",
    "\n",
    "    print(len(split_list),\" files split into train/val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"/Users/ujinne/python/Hackathon/speaker_recognition/data/train/\"\n",
    "split_path = '/Users/ujinne/python/Hackathon/speaker_recognition/data/split.txt'\n",
    "# split_train_val(dir_path, split_path, val_ratio = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ujinne/python/Hackathon/speaker_recognition/data/train/IDMXKDW/eiwfjfklp.pt'"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dir = os.path.join(dir_path, \"IDMXKDW\")\n",
    "utt = \"eiwfjfklp.pt\"\n",
    "\n",
    "os.path.join(save_dir,utt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_val(train_dir, train_path, val_path, val_ratio=0.2):\n",
    "    speakers = [x for x in train_dir.iterdir() if x.is_dir()]\n",
    "    # speakers = sorted([f for f in glob.glob(train_dir + '/*') if os.path.isdir(f)])\n",
    "    print(\"Found \", len(speakers), \"speakers\")\n",
    "    print(speakers)\n",
    "    wav_list = []\n",
    "    train_data = []\n",
    "    val_data = []\n",
    "    for id_ in tqdm(speakers):\n",
    "        utterences = ['/'.join(x.parts[-2:]) for x in id_.glob(\"*.pt\")]\n",
    "        print(utterences)\n",
    "        random.shuffle(utterences)\n",
    "        split_len = len(utterences) - int(len(utterences) * val_ratio)\n",
    "        split_train = utterences[:split_len + 1]\n",
    "        split_val = utterences[split_len+1:]\n",
    "        train_data.extend(split_train)\n",
    "        val_data.extend(split_val)\n",
    "        # split_list.extend((np.random.rand(len(utterences)) > val_ratio).astype(int))\n",
    "        wav_list.extend(utterences)\n",
    "    # save split.txt\n",
    "    with open(train_path, \"w\") as split:\n",
    "        for i, n in enumerate(train_data):\n",
    "            split.write(\"%d %s\\n\" % (n, train_data[i]))\n",
    "    \n",
    "    # with open(val_path, \"w\") as split:\n",
    "    #     for i, n in enumerate(val_data):\n",
    "    #         split.write(\"%d %s\\n\" % (n, val_data[i]))\n",
    "\n",
    "    # print(len(split_list),\" files split into train/val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found  3 speakers\n",
      "[PosixPath('/Users/ujinne/python/Hackathon/speaker_recognition/data/sample/feature/train/0CAE3COBqO'), PosixPath('/Users/ujinne/python/Hackathon/speaker_recognition/data/sample/feature/train/7K4iJllpGl'), PosixPath('/Users/ujinne/python/Hackathon/speaker_recognition/data/sample/feature/train/6cmw8oKHST')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 1818.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0CAE3COBqO/0CAE3COBqO_0.pt', '0CAE3COBqO/0CAE3COBqO_1.pt']\n",
      "['7K4iJllpGl/7K4iJllpGl_1.pt', '7K4iJllpGl/7K4iJllpGl_0.pt']\n",
      "['6cmw8oKHST/6cmw8oKHST_0.pt', '6cmw8oKHST/6cmw8oKHST_1.pt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "%d format: a number is required, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5c/mnjdjb_n1l33vbqt9btclrrw0000gn/T/ipykernel_98455/4255236974.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0msplit_train_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/5c/mnjdjb_n1l33vbqt9btclrrw0000gn/T/ipykernel_98455/2256371716.py\u001b[0m in \u001b[0;36msplit_train_val\u001b[0;34m(train_dir, train_path, val_path, val_ratio)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0msplit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%d %s\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# with open(val_path, \"w\") as split:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: %d format: a number is required, not str"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "train_dir = Path(\"/Users/ujinne/python/Hackathon/speaker_recognition/data/sample/feature/train/\")\n",
    "train_path = Path(\"/Users/ujinne/python/Hackathon/speaker_recognition/data/sample/feature/train/train_data.txt\")\n",
    "val_path = Path(\"/Users/ujinne/python/Hackathon/speaker_recognition/data/sample/feature/train/val_data.txt\")\n",
    "\n",
    "\n",
    "\n",
    "split_train_val(train_dir, train_path, val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False,  True,  True,  True])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(6) > 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GE2ELoss(nn.Module):\n",
    "\n",
    "    def __init__(self, init_w=10.0, init_b=-5.0, loss_method='softmax'):\n",
    "        '''\n",
    "        Implementation of the Generalized End-to-End loss defined in https://arxiv.org/abs/1710.10467 [1]\n",
    "        Accepts an input of size (N, M, D)\n",
    "            where N is the number of speakers in the batch,\n",
    "            M is the number of utterances per speaker,\n",
    "            and D is the dimensionality of the embedding vector (e.g. d-vector)\n",
    "        Args:\n",
    "            - init_w (float): defines the initial value of w in Equation (5) of [1]\n",
    "            - init_b (float): definies the initial value of b in Equation (5) of [1]\n",
    "        '''\n",
    "        super(GE2ELoss, self).__init__()\n",
    "        self.w = nn.Parameter(torch.tensor(init_w))\n",
    "        self.b = nn.Parameter(torch.tensor(init_b))\n",
    "        self.loss_method = loss_method\n",
    "\n",
    "        assert self.loss_method in ['softmax', 'contrast']\n",
    "\n",
    "        if self.loss_method == 'softmax':\n",
    "            self.embed_loss = self.embed_loss_softmax\n",
    "        if self.loss_method == 'contrast':\n",
    "            self.embed_loss = self.embed_loss_contrast\n",
    "\n",
    "    def calc_new_centroids(self, dvecs, centroids, spkr, utt):\n",
    "        '''\n",
    "        Calculates the new centroids excluding the reference utterance\n",
    "        '''\n",
    "        excl = torch.cat((dvecs[spkr,:utt], dvecs[spkr,utt+1:]))\n",
    "        excl = torch.mean(excl, 0)\n",
    "        new_centroids = []\n",
    "        for i, centroid in enumerate(centroids):\n",
    "            if i == spkr:\n",
    "                new_centroids.append(excl)\n",
    "            else:\n",
    "                new_centroids.append(centroid)\n",
    "        return torch.stack(new_centroids)\n",
    "\n",
    "    def calc_cosine_sim(self, dvecs, centroids):\n",
    "        '''\n",
    "        Make the cosine similarity matrix with dims (N,M,N)\n",
    "        '''\n",
    "        cos_sim_matrix = []\n",
    "        for spkr_idx, speaker in enumerate(dvecs):\n",
    "            cs_row = []\n",
    "            for utt_idx, utterance in enumerate(speaker):\n",
    "                new_centroids = self.calc_new_centroids(dvecs, centroids, spkr_idx, utt_idx)\n",
    "                # vector based cosine similarity for speed\n",
    "                cs_row.append(torch.clamp(torch.mm(utterance.unsqueeze(1).transpose(0,1), new_centroids.transpose(0,1)) / (torch.norm(utterance) * torch.norm(new_centroids, dim=1)), 1e-6))\n",
    "            cs_row = torch.cat(cs_row, dim=0)\n",
    "            cos_sim_matrix.append(cs_row)\n",
    "        return torch.stack(cos_sim_matrix)\n",
    "\n",
    "    def embed_loss_softmax(self, dvecs, cos_sim_matrix):\n",
    "        '''\n",
    "        Calculates the loss on each embedding $L(e_{ji})$ by taking softmax\n",
    "        '''\n",
    "        N, M, _ = dvecs.shape\n",
    "        L = []\n",
    "        for j in range(N):\n",
    "            L_row = []\n",
    "            for i in range(M):\n",
    "                L_row.append(-F.log_softmax(cos_sim_matrix[j,i], 0)[j])\n",
    "            L_row = torch.stack(L_row)\n",
    "            L.append(L_row)\n",
    "        return torch.stack(L)\n",
    "\n",
    "    def embed_loss_contrast(self, dvecs, cos_sim_matrix):\n",
    "        ''' \n",
    "        Calculates the loss on each embedding $L(e_{ji})$ by contrast loss with closest centroid\n",
    "        '''\n",
    "        N, M, _ = dvecs.shape\n",
    "        L = []\n",
    "        for j in range(N):\n",
    "            L_row = []\n",
    "            for i in range(M):\n",
    "                centroids_sigmoids = torch.sigmoid(cos_sim_matrix[j,i])\n",
    "                excl_centroids_sigmoids = torch.cat((centroids_sigmoids[:j], centroids_sigmoids[j+1:]))\n",
    "                L_row.append(1. - torch.sigmoid(cos_sim_matrix[j,i,j]) + torch.max(excl_centroids_sigmoids))\n",
    "            L_row = torch.stack(L_row)\n",
    "            L.append(L_row)\n",
    "        return torch.stack(L)\n",
    "\n",
    "    def forward(self, dvecs):\n",
    "        '''\n",
    "        Calculates the GE2E loss for an input of dimensions (num_speakers, num_utts_per_speaker, dvec_feats)\n",
    "        '''\n",
    "        #Calculate centroids\n",
    "        centroids = torch.mean(dvecs, 1)\n",
    "\n",
    "        #Calculate the cosine similarity matrix\n",
    "        cos_sim_matrix = self.calc_cosine_sim(dvecs, centroids)\n",
    "        torch.clamp(self.w, 1e-6)\n",
    "        cos_sim_matrix = cos_sim_matrix * self.w + self.b\n",
    "        L = self.embed_loss(dvecs, cos_sim_matrix)\n",
    "        return L.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2670.7954, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "criterion = GE2ELoss(init_w=10.0, init_b=-5.0, loss_method='softmax') #for softmax loss\n",
    "# criterion = GE2ELoss(init_w=10.0, init_b=-5.0, loss_method='contrast') #for contrast loss\n",
    "\n",
    "N = 64 #Number of speakers in a batch\n",
    "M = 10 #Number of utterances for each speaker\n",
    "D = 256 #Dimensions of the speaker embeddings, such as a d-vector or x-vector\n",
    "\n",
    "test_input = torch.rand(N, M, D)\n",
    "loss = criterion(test_input) #output is a scalar\n",
    "# loss.backward()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.rand(125, 40)\n",
    "sampling_frame_length = 157"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_time = tensor.size(0)\n",
    "feature = tensor.size(1)\n",
    "# print(len_time)\n",
    "# if len_time < sampling_frame_length:\n",
    "#     # print(f'prev_tensor:{utt_tensor.size(0)}')\n",
    "#     # tensor = F.interpolate(tensor.unsqueeze(0), (1, sampling_frame_length,10))\n",
    "#     tensor = F.pad(tensor, (0, 0, , 0), \"constant\", 0)\n",
    "#     print(tensor.shape)\n",
    "#     len_time = tensor.size(0)\n",
    "#     print(f'changed_tensor:{len_time}')\n",
    "# len_time = len_time - sampling_frame_length\n",
    "# # print(f'len_time:{len_time}')\n",
    "# start_time = random.randint(0, len_time)\n",
    "# end_time = start_time + sampling_frame_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "padder = torch.zeros(sampling_frame_length-len_time, feature)\n",
    "padder_a = torch.cat([tensor, padder], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([157, 40])"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padder_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './text/'\n",
    "os.makedirs(path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_meta = pd.read_csv('/Users/ujinne/python/Hackathon/speaker_recognition/data/sample/feature/train_meta.csv')\n",
    "spk_ids = train_meta['id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0CAE3COBqO', '6cmw8oKHST', '7K4iJllpGl']"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spk_ids[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "for spk_id in spk_ids[:-1]:\n",
    "    classes[spk_id] = 3920"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0CAE3COBqO': 3920, '6cmw8oKHST': 3920, '7K4iJllpGl': 3920}"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ujinne/opt/anaconda3/envs/m2m/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = [torch.rand(1, 325, 40).squeeze(0) for _ in range(64)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 325, 40])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.stack(a)\n",
    "a.squeeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.rand(1, 325, 40).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 40])"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = b.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([325, 40])"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(64, 390, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 390)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.transpose(1,2)[0].squeeze(0).detach().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor1 = torch.rand((4,2,3,100))\n",
    "tensor2 = torch.rand((4,2,3,100))\n",
    "tensor1 = tensor1.transpose(1,3)\n",
    "tensor2 = tensor2.transpose(1,3)\n",
    "dist = torch.nn.functional.pairwise_distance(tensor1, tensor2)\n",
    "dist = dist.transpose(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(3, 256)\n",
    "a = torch.mean(a, 0)\n",
    "a = a.unsqueeze(0)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "b = torch.rand(1, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 256])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.cat([b, b], dim=0)\n",
    "b = torch.cat([b, b], dim=0)\n",
    "b = torch.cat([b, b], dim=0)\n",
    "\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 2 nearest neighbors...\n",
      "[t-SNE] Indexed 3 samples in 0.000s...\n",
      "[t-SNE] Computed neighbors for 3 samples in 0.004s...\n",
      "[t-SNE] Computed conditional probabilities for sample 3 / 3\n",
      "[t-SNE] Mean sigma: 1125899906842624.000000\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 35.589149\n",
      "[t-SNE] KL divergence after 300 iterations: 0.000222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300, random_state=256)\n",
    "transformed = tsne.fit_transform(cent.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 18.994495 -19.368113   9.341522  33.315666 -10.998646  36.355682\n",
      "  12.294693  -5.726732] [ 16.530998   -7.064364  -10.278559  -25.611708  -30.41482    -0.9661348\n",
      " -38.797516   13.746578 ]\n"
     ]
    }
   ],
   "source": [
    "print(transformed[:, 0], transformed[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "for i in range(5): \n",
    "    name = [\"dksjg\", \"skuhw\", \"eouw\", \"wogs\", \"skdjg\"]\n",
    "    add =  {\"spk\" : name[i], \"cent\" : torch.rand(1, 256), \"max_di\" : torch.tensor(322.302)}\n",
    "    test.append(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'spk': 'dksjg',\n",
       "  'cent': array([[0.32747275, 0.95415705, 0.05116272, 0.28453445, 0.61130506,\n",
       "          0.8060788 , 0.2526006 , 0.6435509 , 0.906244  , 0.38056356,\n",
       "          0.9541275 , 0.90351903, 0.60839957, 0.42306834, 0.17191082,\n",
       "          0.61234015, 0.26895785, 0.34389615, 0.13387328, 0.79870725,\n",
       "          0.8946097 , 0.27146572, 0.6016372 , 0.2106511 , 0.2703529 ,\n",
       "          0.54561645, 0.44326657, 0.3352247 , 0.8531119 , 0.84005004,\n",
       "          0.94773555, 0.77805305, 0.6083294 , 0.42409253, 0.43590403,\n",
       "          0.90867704, 0.40833598, 0.39948463, 0.5250719 , 0.28788692,\n",
       "          0.8056392 , 0.5286517 , 0.9910353 , 0.5611106 , 0.5842323 ,\n",
       "          0.64239454, 0.90982074, 0.11169189, 0.72790104, 0.21077943,\n",
       "          0.3913222 , 0.11307943, 0.22355461, 0.67547894, 0.9325117 ,\n",
       "          0.7340604 , 0.51652324, 0.26159132, 0.44790006, 0.05375791,\n",
       "          0.85780513, 0.03015476, 0.5606157 , 0.32705408, 0.23939067,\n",
       "          0.20225978, 0.24467689, 0.73079526, 0.48709995, 0.66800433,\n",
       "          0.14957255, 0.4570446 , 0.29356486, 0.81883156, 0.24298185,\n",
       "          0.6769401 , 0.6253741 , 0.97591126, 0.6020491 , 0.9601047 ,\n",
       "          0.44652534, 0.2157076 , 0.02058005, 0.72462213, 0.26365834,\n",
       "          0.97503376, 0.24158901, 0.88914514, 0.7909538 , 0.78447086,\n",
       "          0.6413707 , 0.29446036, 0.5121435 , 0.37119395, 0.7708557 ,\n",
       "          0.5734766 , 0.49791247, 0.42822534, 0.67398584, 0.6601889 ,\n",
       "          0.45367956, 0.01810282, 0.7630475 , 0.77186084, 0.40497667,\n",
       "          0.29794985, 0.05457985, 0.06270438, 0.19490296, 0.60035557,\n",
       "          0.06769717, 0.91424495, 0.6635332 , 0.02161622, 0.76062346,\n",
       "          0.45649815, 0.00782758, 0.18188316, 0.58185184, 0.5964743 ,\n",
       "          0.3406217 , 0.7771395 , 0.76451755, 0.43079263, 0.38183594,\n",
       "          0.7126813 , 0.11477911, 0.559726  , 0.06483138, 0.23912185,\n",
       "          0.66019124, 0.14713311, 0.74517524, 0.4055282 , 0.15368795,\n",
       "          0.06592524, 0.49977326, 0.09236699, 0.9813027 , 0.80856466,\n",
       "          0.96181875, 0.27916294, 0.72517896, 0.9997862 , 0.00558311,\n",
       "          0.02615184, 0.19716716, 0.11570466, 0.98247707, 0.22201872,\n",
       "          0.70210886, 0.8513595 , 0.40337104, 0.68906033, 0.9782273 ,\n",
       "          0.96322405, 0.6986933 , 0.38406187, 0.1274041 , 0.6163718 ,\n",
       "          0.46707112, 0.9593347 , 0.816605  , 0.9101335 , 0.01062346,\n",
       "          0.7670008 , 0.2949531 , 0.63829505, 0.25719965, 0.88443893,\n",
       "          0.8581546 , 0.0502919 , 0.4430945 , 0.81696415, 0.7098418 ,\n",
       "          0.87357676, 0.09326565, 0.57387275, 0.18790406, 0.10425097,\n",
       "          0.35399878, 0.7036013 , 0.25898415, 0.6335784 , 0.16223991,\n",
       "          0.10326177, 0.91136616, 0.47894913, 0.97465116, 0.15751487,\n",
       "          0.3971387 , 0.6467881 , 0.39942414, 0.13302398, 0.63830966,\n",
       "          0.58504623, 0.36617446, 0.5148291 , 0.9479248 , 0.55207795,\n",
       "          0.69530725, 0.3662687 , 0.48502016, 0.46511453, 0.4887752 ,\n",
       "          0.65920687, 0.9098926 , 0.62550676, 0.22905731, 0.67194283,\n",
       "          0.84850025, 0.17227507, 0.8718918 , 0.95783293, 0.4843825 ,\n",
       "          0.50113165, 0.08142918, 0.87772447, 0.12297285, 0.87991107,\n",
       "          0.44110632, 0.5513137 , 0.6102528 , 0.39160752, 0.23511541,\n",
       "          0.38110036, 0.35856742, 0.55217683, 0.40409547, 0.15135235,\n",
       "          0.6274638 , 0.8446853 , 0.27969927, 0.6486899 , 0.27259356,\n",
       "          0.6605967 , 0.14482677, 0.9236808 , 0.22708029, 0.57127297,\n",
       "          0.28861827, 0.93985885, 0.9552093 , 0.36142713, 0.81583244,\n",
       "          0.11257404, 0.39859736, 0.3692974 , 0.3007788 , 0.7510884 ,\n",
       "          0.89375955, 0.4014992 , 0.39569825, 0.2671011 , 0.4404509 ,\n",
       "          0.637791  ]], dtype=float32),\n",
       "  'max_di': array(322.302, dtype=float32)},\n",
       " {'spk': 'skuhw',\n",
       "  'cent': array([[6.36150837e-01, 6.85926437e-01, 2.16455817e-01, 5.70736229e-01,\n",
       "          8.53093863e-01, 5.63703835e-01, 3.93296361e-01, 4.40303862e-01,\n",
       "          1.79260671e-01, 1.92472279e-01, 9.71031010e-01, 3.79556835e-01,\n",
       "          1.81834161e-01, 1.49182677e-01, 5.79211354e-01, 6.44612908e-02,\n",
       "          8.80101204e-01, 8.35579276e-01, 7.54213035e-01, 9.92872119e-01,\n",
       "          9.30097818e-01, 1.61398113e-01, 9.22391593e-01, 8.19889784e-01,\n",
       "          4.53450263e-01, 1.24855042e-02, 6.60835624e-01, 3.87808621e-01,\n",
       "          9.24833179e-01, 8.14095736e-02, 5.10114431e-01, 9.48927522e-01,\n",
       "          8.62096429e-01, 3.81837130e-01, 7.97792077e-01, 1.97989047e-01,\n",
       "          8.98145318e-01, 2.35217214e-02, 4.61579263e-01, 7.26578534e-01,\n",
       "          7.09087431e-01, 7.36445308e-01, 5.86204290e-01, 4.33432162e-01,\n",
       "          4.53554392e-02, 6.79096997e-01, 6.96165562e-02, 3.36415052e-01,\n",
       "          2.91755795e-02, 1.18928134e-01, 1.18522525e-01, 6.71402395e-01,\n",
       "          3.05249751e-01, 4.27516997e-01, 9.55190063e-01, 9.23401713e-02,\n",
       "          2.68363953e-03, 8.93429339e-01, 1.41661882e-01, 2.60499060e-01,\n",
       "          7.30949879e-01, 7.92828858e-01, 6.26039326e-01, 4.37795043e-01,\n",
       "          7.72287965e-01, 6.70353830e-01, 9.28076208e-01, 9.60780680e-01,\n",
       "          4.29462194e-01, 6.96996450e-02, 8.57413888e-01, 8.97752464e-01,\n",
       "          5.71932852e-01, 7.11061358e-02, 4.72828925e-01, 8.98467541e-01,\n",
       "          1.77394032e-01, 5.80587685e-01, 5.97209990e-01, 4.72715914e-01,\n",
       "          7.00872302e-01, 1.23695374e-01, 2.01038778e-01, 9.75185931e-01,\n",
       "          9.72175837e-01, 7.87191272e-01, 7.92300105e-01, 9.17302728e-01,\n",
       "          7.91968882e-01, 4.42558646e-01, 9.30940509e-01, 7.44603813e-01,\n",
       "          1.91977441e-01, 4.92216647e-01, 9.44481909e-01, 1.25299871e-01,\n",
       "          3.11678052e-02, 3.10146272e-01, 9.29614365e-01, 6.01437569e-01,\n",
       "          8.41330588e-01, 9.85078514e-01, 5.71918547e-01, 8.71500134e-01,\n",
       "          6.66566372e-01, 1.78006291e-02, 3.55812848e-01, 9.42045569e-01,\n",
       "          3.34032774e-01, 6.86979294e-03, 7.88731575e-02, 9.31132793e-01,\n",
       "          7.53939509e-01, 9.13837075e-01, 9.98018920e-01, 9.84961987e-01,\n",
       "          1.11389875e-01, 2.68895626e-02, 4.04176831e-01, 8.12050760e-01,\n",
       "          3.68803144e-02, 2.04000413e-01, 7.21015930e-01, 3.87703180e-02,\n",
       "          9.63352442e-01, 7.34379113e-01, 6.71142340e-03, 9.65382934e-01,\n",
       "          3.92688215e-01, 2.94140875e-01, 7.06252098e-01, 3.98011804e-02,\n",
       "          9.05851185e-01, 5.04430294e-01, 5.86628914e-01, 6.84450865e-02,\n",
       "          2.28672981e-01, 9.74450231e-01, 1.49765432e-01, 1.16985261e-01,\n",
       "          5.06772757e-01, 2.54786730e-01, 6.56698644e-01, 9.95488524e-01,\n",
       "          6.94793701e-01, 1.20438457e-01, 6.86383665e-01, 8.20637822e-01,\n",
       "          3.54941487e-02, 3.55694592e-01, 7.55515397e-01, 5.99356055e-01,\n",
       "          8.37250948e-01, 1.74343586e-04, 6.47171259e-01, 6.10806406e-01,\n",
       "          5.85103393e-01, 6.24782145e-01, 7.36438215e-01, 4.90725935e-01,\n",
       "          6.90781951e-01, 7.20098019e-01, 6.10459149e-01, 7.61573851e-01,\n",
       "          2.65969992e-01, 8.64631355e-01, 9.57346559e-01, 8.69892240e-01,\n",
       "          3.47498298e-01, 9.36949432e-01, 9.91985857e-01, 5.17134368e-01,\n",
       "          4.01430726e-01, 8.99377882e-01, 9.24272656e-01, 1.11005604e-01,\n",
       "          6.09974325e-01, 4.41055834e-01, 4.99836087e-01, 9.22695398e-01,\n",
       "          7.39155412e-02, 5.59974372e-01, 7.79894471e-01, 4.10227895e-01,\n",
       "          1.08871281e-01, 5.23014843e-01, 3.52865458e-01, 5.69146931e-01,\n",
       "          7.25240469e-01, 6.81751370e-02, 4.62501764e-01, 6.84940279e-01,\n",
       "          1.75417900e-01, 8.95079970e-02, 5.90584874e-02, 4.99340832e-01,\n",
       "          3.77609730e-01, 7.21600056e-02, 8.72542262e-01, 7.25630820e-01,\n",
       "          6.91096365e-01, 4.38236058e-01, 7.66457438e-01, 6.25347137e-01,\n",
       "          5.67010641e-02, 9.76105690e-01, 1.06550634e-01, 3.09730530e-01,\n",
       "          2.36270666e-01, 3.91530395e-02, 4.88081574e-02, 5.95005691e-01,\n",
       "          5.05957663e-01, 4.53463137e-01, 8.21963787e-01, 2.56797612e-01,\n",
       "          4.10584867e-01, 5.99845946e-01, 1.87086463e-02, 1.46121860e-01,\n",
       "          3.11410248e-01, 6.90947056e-01, 4.69323516e-01, 4.03217435e-01,\n",
       "          1.45076156e-01, 7.82986462e-01, 8.57956171e-01, 5.63718617e-01,\n",
       "          7.27547884e-01, 5.44748068e-01, 8.84403288e-01, 3.94915938e-02,\n",
       "          7.03713119e-01, 3.06475878e-01, 3.75066280e-01, 8.14597070e-01,\n",
       "          2.32483566e-01, 7.75192618e-01, 5.11983037e-01, 2.86779344e-01,\n",
       "          3.82825136e-02, 2.71681130e-01, 3.86154294e-01, 4.94826674e-01,\n",
       "          9.72711563e-01, 2.45581388e-01, 1.37035847e-02, 9.10047472e-01,\n",
       "          4.98216033e-01, 1.47862434e-01, 2.89412081e-01, 5.96336424e-01,\n",
       "          2.07623363e-01, 1.58041716e-02, 8.02433133e-01, 4.65644598e-02]],\n",
       "        dtype=float32),\n",
       "  'max_di': array(322.302, dtype=float32)},\n",
       " {'spk': 'eouw',\n",
       "  'cent': array([[0.76808846, 0.63329846, 0.7347685 , 0.03685063, 0.9067875 ,\n",
       "          0.7210328 , 0.0347507 , 0.23244435, 0.36570412, 0.57960796,\n",
       "          0.3991617 , 0.62762296, 0.2843364 , 0.97722507, 0.63997036,\n",
       "          0.23668754, 0.6355445 , 0.4977638 , 0.8322261 , 0.15701413,\n",
       "          0.1584295 , 0.73339635, 0.59944224, 0.821292  , 0.53867596,\n",
       "          0.62272763, 0.7843952 , 0.17608714, 0.7905748 , 0.9936078 ,\n",
       "          0.10553658, 0.3413387 , 0.6447897 , 0.6109696 , 0.51054335,\n",
       "          0.60655797, 0.21082097, 0.23153949, 0.10784411, 0.65866506,\n",
       "          0.76744074, 0.8410173 , 0.24198896, 0.05364144, 0.42631775,\n",
       "          0.94755566, 0.7132661 , 0.20266551, 0.77936304, 0.64003617,\n",
       "          0.7401929 , 0.25545126, 0.51624936, 0.4206056 , 0.3536262 ,\n",
       "          0.26229692, 0.64770657, 0.85514927, 0.7145237 , 0.7426107 ,\n",
       "          0.5879976 , 0.6373872 , 0.558859  , 0.7883388 , 0.7171251 ,\n",
       "          0.89320827, 0.9806058 , 0.90128833, 0.99889016, 0.30881512,\n",
       "          0.23491299, 0.8994274 , 0.47095573, 0.06429356, 0.10125077,\n",
       "          0.80942225, 0.14262444, 0.336518  , 0.69879675, 0.09459805,\n",
       "          0.6654407 , 0.9037897 , 0.46895248, 0.3912354 , 0.79995334,\n",
       "          0.16999573, 0.10598594, 0.6727781 , 0.72993296, 0.94818705,\n",
       "          0.690641  , 0.4889893 , 0.28830683, 0.423137  , 0.42899418,\n",
       "          0.08767939, 0.5097507 , 0.6720045 , 0.01852274, 0.06860757,\n",
       "          0.9046504 , 0.02605313, 0.9126835 , 0.4620992 , 0.31416196,\n",
       "          0.827522  , 0.54326665, 0.5766956 , 0.8004683 , 0.37463516,\n",
       "          0.5681448 , 0.21583337, 0.97614455, 0.3800295 , 0.5897353 ,\n",
       "          0.13884217, 0.95587885, 0.43548304, 0.7269323 , 0.5336201 ,\n",
       "          0.3025686 , 0.32062852, 0.18735623, 0.7365601 , 0.39464015,\n",
       "          0.8134323 , 0.9355417 , 0.7395751 , 0.86871725, 0.23125798,\n",
       "          0.876959  , 0.97242945, 0.91429603, 0.5436445 , 0.5428334 ,\n",
       "          0.33809638, 0.38951153, 0.58213997, 0.8926055 , 0.7207298 ,\n",
       "          0.5922415 , 0.5524008 , 0.81712824, 0.02366614, 0.7060849 ,\n",
       "          0.15318543, 0.9353158 , 0.49490935, 0.37671423, 0.60778266,\n",
       "          0.5154979 , 0.2678777 , 0.93988466, 0.411335  , 0.01995134,\n",
       "          0.10386807, 0.82025814, 0.624012  , 0.23363107, 0.07030469,\n",
       "          0.66330284, 0.82812023, 0.01179624, 0.2622125 , 0.73180866,\n",
       "          0.4321891 , 0.07452488, 0.77949893, 0.8199171 , 0.961071  ,\n",
       "          0.3125248 , 0.38489866, 0.34301805, 0.67048866, 0.50979674,\n",
       "          0.88928753, 0.7734026 , 0.33606726, 0.02821344, 0.821478  ,\n",
       "          0.08378017, 0.8786901 , 0.7183989 , 0.27536398, 0.313048  ,\n",
       "          0.8157645 , 0.09856457, 0.5403877 , 0.83739686, 0.73345333,\n",
       "          0.7563295 , 0.8694077 , 0.03464741, 0.9594161 , 0.5085267 ,\n",
       "          0.13294935, 0.42942733, 0.98882157, 0.38047922, 0.9276543 ,\n",
       "          0.6309154 , 0.35538656, 0.7986897 , 0.09144884, 0.5509976 ,\n",
       "          0.58538026, 0.21751654, 0.9269052 , 0.00821143, 0.46685553,\n",
       "          0.48215467, 0.16737032, 0.7275106 , 0.67807066, 0.05757982,\n",
       "          0.8975342 , 0.3957616 , 0.59831107, 0.9034236 , 0.26631987,\n",
       "          0.824519  , 0.21891898, 0.73732466, 0.15522712, 0.60284054,\n",
       "          0.73489726, 0.09739518, 0.85444516, 0.28723508, 0.217242  ,\n",
       "          0.8681989 , 0.8593465 , 0.32326454, 0.985012  , 0.38104558,\n",
       "          0.30716562, 0.7979653 , 0.8891888 , 0.20916945, 0.52453756,\n",
       "          0.98948336, 0.94029355, 0.7300739 , 0.7904687 , 0.17429078,\n",
       "          0.979071  , 0.9484494 , 0.48125833, 0.20148814, 0.44113123,\n",
       "          0.2533937 , 0.811476  , 0.5801717 , 0.43827552, 0.15903926,\n",
       "          0.32923508]], dtype=float32),\n",
       "  'max_di': array(322.302, dtype=float32)},\n",
       " {'spk': 'wogs',\n",
       "  'cent': array([[0.6981505 , 0.10260117, 0.2554893 , 0.83318645, 0.77801967,\n",
       "          0.7513987 , 0.4188245 , 0.7889813 , 0.5011838 , 0.86548704,\n",
       "          0.24743992, 0.6261039 , 0.49855173, 0.46379733, 0.78306514,\n",
       "          0.40672034, 0.16522503, 0.5633132 , 0.2642805 , 0.34668618,\n",
       "          0.2485258 , 0.304218  , 0.25698578, 0.8428323 , 0.30474234,\n",
       "          0.97392356, 0.36086017, 0.12054265, 0.7233368 , 0.93355507,\n",
       "          0.85381716, 0.8194003 , 0.13493711, 0.25159132, 0.73297435,\n",
       "          0.10311311, 0.90263987, 0.83769584, 0.9528387 , 0.43857223,\n",
       "          0.67063516, 0.96394205, 0.17999512, 0.7751961 , 0.45833427,\n",
       "          0.97258556, 0.6155124 , 0.11092126, 0.29047048, 0.5261598 ,\n",
       "          0.73082995, 0.8566686 , 0.4528635 , 0.92780006, 0.16933197,\n",
       "          0.09043372, 0.28148842, 0.3433869 , 0.7509758 , 0.23446667,\n",
       "          0.26344627, 0.54454416, 0.95911425, 0.6265706 , 0.17282921,\n",
       "          0.93815064, 0.76538545, 0.6390125 , 0.7261488 , 0.59691805,\n",
       "          0.18029636, 0.18299472, 0.4757794 , 0.336214  , 0.25487083,\n",
       "          0.48702115, 0.39850742, 0.4979598 , 0.5129967 , 0.28496903,\n",
       "          0.05683917, 0.6171275 , 0.768935  , 0.78431624, 0.5257422 ,\n",
       "          0.886075  , 0.68030536, 0.0560438 , 0.82762945, 0.7478831 ,\n",
       "          0.41977632, 0.18414646, 0.36831307, 0.60376793, 0.67718995,\n",
       "          0.97035533, 0.7717953 , 0.5175038 , 0.33919984, 0.21072924,\n",
       "          0.5964055 , 0.7250693 , 0.2968797 , 0.99670655, 0.39681298,\n",
       "          0.811731  , 0.62784755, 0.11975098, 0.17206907, 0.8026364 ,\n",
       "          0.96776843, 0.46300387, 0.7073482 , 0.08392501, 0.48006213,\n",
       "          0.67379004, 0.3962379 , 0.17630851, 0.28831875, 0.31198627,\n",
       "          0.66654444, 0.6252239 , 0.561455  , 0.9876514 , 0.19069958,\n",
       "          0.584998  , 0.6628048 , 0.00436497, 0.66944623, 0.6922593 ,\n",
       "          0.3181584 , 0.6415988 , 0.41771907, 0.8017306 , 0.6860387 ,\n",
       "          0.5931637 , 0.36508548, 0.880439  , 0.28634113, 0.16118735,\n",
       "          0.6773065 , 0.70417255, 0.39418328, 0.50389737, 0.21007615,\n",
       "          0.32453364, 0.36068612, 0.79238015, 0.7885979 , 0.4049973 ,\n",
       "          0.78449225, 0.25544858, 0.01810926, 0.96553487, 0.5737364 ,\n",
       "          0.4080444 , 0.7711224 , 0.16217393, 0.15822148, 0.81794226,\n",
       "          0.7045112 , 0.9794939 , 0.06131804, 0.92959183, 0.6138303 ,\n",
       "          0.11675388, 0.96426785, 0.27331597, 0.70682013, 0.95322305,\n",
       "          0.8811881 , 0.16010976, 0.37002653, 0.05672151, 0.39544725,\n",
       "          0.0776999 , 0.28580844, 0.25627422, 0.01202542, 0.3654881 ,\n",
       "          0.0437268 , 0.66478765, 0.16468579, 0.48613125, 0.9681358 ,\n",
       "          0.9186966 , 0.20601422, 0.3755926 , 0.4492426 , 0.47680575,\n",
       "          0.6883319 , 0.794542  , 0.9179886 , 0.8644382 , 0.70165825,\n",
       "          0.56406575, 0.4309035 , 0.9400034 , 0.6556685 , 0.33182138,\n",
       "          0.26851392, 0.5712839 , 0.52408636, 0.6328827 , 0.67112875,\n",
       "          0.09285104, 0.5643349 , 0.94825107, 0.94126475, 0.71961814,\n",
       "          0.05407149, 0.59543574, 0.5634417 , 0.33984756, 0.22218883,\n",
       "          0.6544824 , 0.28221565, 0.17482036, 0.3133307 , 0.14572734,\n",
       "          0.29853302, 0.9925695 , 0.3406664 , 0.6833426 , 0.6383542 ,\n",
       "          0.9470701 , 0.9333308 , 0.85576296, 0.63886327, 0.66955477,\n",
       "          0.09410387, 0.55061156, 0.5872091 , 0.86769193, 0.94269633,\n",
       "          0.32244802, 0.4227962 , 0.47904986, 0.11825818, 0.7316814 ,\n",
       "          0.5582024 , 0.20731378, 0.0210169 , 0.9667566 , 0.78555346,\n",
       "          0.6248654 , 0.13205475, 0.4078722 , 0.21778643, 0.11872548,\n",
       "          0.8712045 , 0.06906801, 0.87715685, 0.07456398, 0.3296669 ,\n",
       "          0.965587  ]], dtype=float32),\n",
       "  'max_di': array(322.302, dtype=float32)},\n",
       " {'spk': 'skdjg',\n",
       "  'cent': array([[0.89145994, 0.53054637, 0.8595887 , 0.35445172, 0.04493457,\n",
       "          0.82033235, 0.85651433, 0.51614   , 0.8150083 , 0.15656263,\n",
       "          0.5798936 , 0.52908784, 0.96156734, 0.4307626 , 0.9585028 ,\n",
       "          0.26790792, 0.4221998 , 0.14126265, 0.8175276 , 0.47281337,\n",
       "          0.33024514, 0.53694546, 0.0054425 , 0.48612875, 0.5463022 ,\n",
       "          0.5514114 , 0.13511151, 0.17734909, 0.16648144, 0.03969842,\n",
       "          0.36082786, 0.59759474, 0.6172552 , 0.7521005 , 0.51302105,\n",
       "          0.02365404, 0.21262455, 0.8996263 , 0.11415148, 0.28007936,\n",
       "          0.7681479 , 0.28346336, 0.77217966, 0.86139244, 0.93276054,\n",
       "          0.9618162 , 0.13891977, 0.22517335, 0.1866824 , 0.75622624,\n",
       "          0.6513672 , 0.63482666, 0.11368656, 0.7294974 , 0.45098603,\n",
       "          0.9750306 , 0.9407542 , 0.09805942, 0.9754278 , 0.34994304,\n",
       "          0.22089875, 0.37081784, 0.41821527, 0.5776238 , 0.06789708,\n",
       "          0.30194968, 0.05215633, 0.50460964, 0.58908594, 0.14408821,\n",
       "          0.69446206, 0.07389671, 0.02471876, 0.5813138 , 0.09755963,\n",
       "          0.10551769, 0.65213597, 0.7239259 , 0.36987615, 0.85797465,\n",
       "          0.9757814 , 0.80594796, 0.72196597, 0.02405876, 0.7485948 ,\n",
       "          0.10241646, 0.10048741, 0.7658006 , 0.44306052, 0.9824399 ,\n",
       "          0.48459798, 0.74349684, 0.02360713, 0.6885272 , 0.7688174 ,\n",
       "          0.5477342 , 0.5629514 , 0.9008282 , 0.6638321 , 0.63586193,\n",
       "          0.8903849 , 0.85156375, 0.26317936, 0.26013398, 0.8372719 ,\n",
       "          0.79408777, 0.10511041, 0.6161966 , 0.66271347, 0.10088795,\n",
       "          0.50013363, 0.66611457, 0.28665352, 0.73606485, 0.2357235 ,\n",
       "          0.44382644, 0.04062933, 0.661179  , 0.7109184 , 0.5846956 ,\n",
       "          0.7462932 , 0.05131263, 0.34374803, 0.34413302, 0.29862285,\n",
       "          0.42628878, 0.8893348 , 0.4825716 , 0.5208038 , 0.85144   ,\n",
       "          0.6549006 , 0.06483215, 0.7683469 , 0.16089761, 0.5627813 ,\n",
       "          0.4831372 , 0.61104465, 0.42556077, 0.5015084 , 0.22080791,\n",
       "          0.46369845, 0.48671335, 0.5219536 , 0.21035099, 0.54710335,\n",
       "          0.00100118, 0.48850995, 0.25013334, 0.6702033 , 0.25482684,\n",
       "          0.73852384, 0.03257424, 0.29369694, 0.4793198 , 0.8479577 ,\n",
       "          0.23963857, 0.87775654, 0.6463708 , 0.20734006, 0.8574262 ,\n",
       "          0.61092   , 0.68866533, 0.83419347, 0.37922156, 0.2823174 ,\n",
       "          0.7321853 , 0.56780136, 0.72918296, 0.36251307, 0.12076372,\n",
       "          0.33532846, 0.90221685, 0.746408  , 0.48472124, 0.41038042,\n",
       "          0.05016035, 0.88497835, 0.32431376, 0.5519479 , 0.90048665,\n",
       "          0.61824304, 0.11485541, 0.4799084 , 0.6481988 , 0.57884735,\n",
       "          0.6519848 , 0.5024389 , 0.47775298, 0.7844687 , 0.20323098,\n",
       "          0.791944  , 0.74642426, 0.95419306, 0.02069205, 0.10379475,\n",
       "          0.8675608 , 0.8471482 , 0.08914006, 0.85722   , 0.36702836,\n",
       "          0.6538237 , 0.9785229 , 0.02401537, 0.08248585, 0.613226  ,\n",
       "          0.18624294, 0.7783116 , 0.4544207 , 0.9857521 , 0.7017134 ,\n",
       "          0.07762641, 0.63063383, 0.8917354 , 0.72045076, 0.65106   ,\n",
       "          0.01451182, 0.6215082 , 0.7616093 , 0.7618089 , 0.9721326 ,\n",
       "          0.693964  , 0.22136599, 0.89465564, 0.95213926, 0.02037513,\n",
       "          0.15282542, 0.48184085, 0.93359524, 0.80326253, 0.27144134,\n",
       "          0.2887138 , 0.11296278, 0.22408903, 0.5168852 , 0.194861  ,\n",
       "          0.6189029 , 0.49524826, 0.24159306, 0.2834003 , 0.48623073,\n",
       "          0.22302544, 0.42433852, 0.7277511 , 0.6421929 , 0.5065969 ,\n",
       "          0.82000285, 0.88342464, 0.56377864, 0.77086985, 0.50240314,\n",
       "          0.98200375, 0.86707175, 0.2298013 , 0.9875893 , 0.08972889,\n",
       "          0.59567314]], dtype=float32),\n",
       "  'max_di': array(322.302, dtype=float32)}]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dvecs = torch.rand(3, 140, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 256])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cent = torch.mean(dvecs, dim=1)\n",
    "cent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4970, 0.4703, 0.5007])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "test_dir = './data/sample/feature/test'\n",
    "\n",
    "utts = [f for f in glob.glob(test_dir + '/*.pt') if os.path.isfile(f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording = [f.split('/')[-1].replace(\".pt\", \".wav\") for f in utts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['owemm8FAOM_0.wav',\n",
       " 'owemm8FAOM_1.wav',\n",
       " 'mtNgnWp7R8_0.wav',\n",
       " 'mtNgnWp7R8_1.wav']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# from torchmetrics.functional import pairwise_euclidean_distance\n",
    "\n",
    "x = torch.rand(1, 256)\n",
    "y = torch.rand(1, 256)\n",
    "\n",
    "# print(pairwise_euclidean_distance(x, y))\n",
    "print(torch.cdist(x, y, p=2).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6.3092])\n"
     ]
    }
   ],
   "source": [
    "print(torch.sqrt(((x-y)**2).sum(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6.3092])\n"
     ]
    }
   ],
   "source": [
    "dist = torch.nn.PairwiseDistance(p=2)\n",
    "print(dist(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "max_dis = np.array(322.302)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = torch.cdist(x, y, p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.9463]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dist.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.3092])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.9463]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = [dist, a]\n",
    "max(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ujinne/opt/anaconda3/envs/m2m/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "import webrtcvad\n",
    "vad = webrtcvad.Vad(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "from typing import Optional, Union\n",
    "from pathlib import Path\n",
    "\n",
    "sampling_rate = 16000\n",
    "\n",
    "def preprocess_wav(fpath_or_wav: Union[str, Path, np.ndarray],\n",
    "                   source_sr: Optional[int] = None):\n",
    "    # Load the wav from disk if needed\n",
    "    if isinstance(fpath_or_wav, str) or isinstance(fpath_or_wav, Path):\n",
    "        wav, source_sr = librosa.load(fpath_or_wav, sr=None)\n",
    "    else:\n",
    "        wav = fpath_or_wav\n",
    "\n",
    "    # Resample the wav if needed\n",
    "    if source_sr is not None and source_sr != sampling_rate:\n",
    "        wav = librosa.resample(wav, source_sr, sampling_rate)\n",
    "    # print(type(wav))\n",
    "\n",
    "    # trim audio\n",
    "    wav = torchaudio.functional.vad(torch.from_numpy(wav), source_sr)\n",
    "\n",
    "    # # Apply the preprocessing: normalize volume and shorten long silences\n",
    "    # wav = normalize_volume(wav, audio_norm_target_dBFS, increase_only=True)\n",
    "\n",
    "    return np.array(wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50415,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/Users/ujinne/python/Hackathon/speaker_recognition/data/sample/train/mtNgnWp7R8/mtNgnWp7R8_1.wav'\n",
    "wav = preprocess_wav(path)\n",
    "wav.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import write\n",
    "\n",
    "write(\"example.wav\", 16000, wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 69615])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wav, sr = torchaudio.load(path)\n",
    "wav.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69615,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wav, source_sr = librosa.load(path, sr=None)\n",
    "wav.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1, 'b': 2, 'c': 3, 'e': 4}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic = {'a': 1, 'b': 2, 'c':3}\n",
    "dic['e'] = len(dic)+1\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic.get('e', 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.rand(1, 3124)\n",
    "# tgt = torch.randint(0, 10, (640,))\n",
    "tgt = torch.randint(0, 3124, (640,))\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "input = torch.randn(640, 3183)\n",
    "labels = torch.randint(0, 3183, (640,))\n",
    "target = torch.zeros_like(input)\n",
    "target.scatter_(1, labels.unsqueeze(1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "softmax() received an invalid combination of arguments - got (Tensor), but expected one of:\n * (Tensor input, int dim, torch.dtype dtype)\n * (Tensor input, name dim, *, torch.dtype dtype)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/ujinne/python/Hackathon/speaker_recognition/test.ipynb Cell 32'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ujinne/python/Hackathon/speaker_recognition/test.ipynb#ch0000031?line=0'>1</a>\u001b[0m probs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49msoftmax(out)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ujinne/python/Hackathon/speaker_recognition/test.ipynb#ch0000031?line=1'>2</a>\u001b[0m \u001b[39m# probs = probs.max(dim=1)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ujinne/python/Hackathon/speaker_recognition/test.ipynb#ch0000031?line=2'>3</a>\u001b[0m \u001b[39m# probs = probs.argmax(dim=1)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ujinne/python/Hackathon/speaker_recognition/test.ipynb#ch0000031?line=3'>4</a>\u001b[0m probs\n",
      "\u001b[0;31mTypeError\u001b[0m: softmax() received an invalid combination of arguments - got (Tensor), but expected one of:\n * (Tensor input, int dim, torch.dtype dtype)\n * (Tensor input, name dim, *, torch.dtype dtype)\n"
     ]
    }
   ],
   "source": [
    "probs = torch.softmax(out)\n",
    "# probs = probs.max(dim=1)\n",
    "# probs = probs.argmax(dim=1)\n",
    "probs\n",
    "# torch.max(out.softmax(-1)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'values' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/ujinne/python/Hackathon/speaker_recognition/test.ipynb Cell 102'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ujinne/python/Hackathon/speaker_recognition/test.ipynb#ch0000112?line=0'>1</a>\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mmax(values\u001b[39m.\u001b[39msoftmax(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mitem() \u001b[39m<\u001b[39m threshold:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ujinne/python/Hackathon/speaker_recognition/test.ipynb#ch0000112?line=1'>2</a>\u001b[0m    prediction \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39munknown\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'values' is not defined"
     ]
    }
   ],
   "source": [
    " if torch.max(values.softmax(-1)).item() < threshold:\n",
    "    prediction = 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        print(f'pred.shape:{pred.shape}')\n",
    "        pred = pred.t() #transpose\n",
    "        print(f'pred.shape:{pred.shape}')\n",
    "        print(f'target.shape:{target.shape}')\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "        print(f'target: {target.view(1, -1).expand_as(pred)}')\n",
    "        print(f'pred: {pred}')\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(cfg, output, topk=(1,), threshold=0.5):\n",
    "    dataset_root = Path(cfg.DATASET.DATA_DIR)\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = 1\n",
    "\n",
    "        values, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "\n",
    "        # Getting the most probable speaker_id(str)\n",
    "        prediction = find_id(dataset_root, pred[0][0].item())\n",
    "\n",
    "        # Custom\n",
    "        if torch.max(values.softmax(-1)).item() < threshold:\n",
    "            prediction = 'unknown'\n",
    "\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "values:tensor([[0.9995]])\n",
      "pred:tensor([[481]])\n",
      "pred:torch.Size([1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk = (1,)\n",
    "maxk = max(topk)\n",
    "values, pred = out.topk(maxk, 1, True, True)\n",
    "print(f'values:{values}')\n",
    "print(f'pred:{pred}')\n",
    "print(f'pred:{pred.shape}')\n",
    "pred = pred.t()\n",
    "\n",
    "torch.max(values.softmax(-1)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(values.softmax(-1)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nsml_package.txt',\n",
       " 'baseline_code',\n",
       " '.DS_Store',\n",
       " 'main_stt1.ipynb',\n",
       " 'requirements.txt',\n",
       " 'Lipreading_final',\n",
       " 'Makefile',\n",
       " 'main_stt1.py',\n",
       " 'AudioVisualLoss.ipynb',\n",
       " 'stt_model.py',\n",
       " '__pycache__',\n",
       " 'setup.py',\n",
       " 'conformer',\n",
       " 'main_stt2.py',\n",
       " 'fps_changer.py',\n",
       " 'checkpoint.tar',\n",
       " '.ipynb_checkpoints',\n",
       " 'data',\n",
       " 'data.py']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/Users/ujinne/python/Hackathon/Lipreading/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6333667f5006331eb0f16d3e1b321b3f508046c9e940d9edc2ea9dfab6c9faf6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('m2m')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
